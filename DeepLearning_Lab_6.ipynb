{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Atharv24-Atreus/Deep-Learning-Lab/blob/main/DeepLearning_Lab_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2-Pi-kfTpwiA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nsXyA8ip1EG",
        "outputId": "13d8fdd0-f364-44ca-f52a-2f272247643d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(-1, 784).astype('float32')  # Flatten the images\n",
        "train_images = (train_images- 127.5) / 127.5  # Normalize to [-1, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zwCS-20Up8om"
      },
      "outputs": [],
      "source": [
        " BUFFER_SIZE = 60000\n",
        " BATCH_SIZE = 256\n",
        " EPOCHS = 50\n",
        " NOISE_DIM = 100\n",
        " NUM_EXAMPLES_TO_GENERATE = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6GEcMT4AqJht"
      },
      "outputs": [],
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FzJdmmbqqXbn"
      },
      "outputs": [],
      "source": [
        " def make_generator_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Dense(256, use_bias=False, input_shape=(NOISE_DIM,)),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dense(512, use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dense(1024, use_bias=False),\n",
        "      layers.BatchNormalization(),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dense(784, use_bias=False, activation='tanh') # Output shape (None, 784)\n",
        "      ])\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6gS8AJYyqgLT"
      },
      "outputs": [],
      "source": [
        "def make_discriminator_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      layers.Dense(1024, input_shape=(784,)),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(512),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "      layers.Dense(256),\n",
        "      layers.LeakyReLU(),\n",
        "      layers.Dropout(0.3),\n",
        "      ])\n",
        "  layers.Dense(1) # Output shape (None, 1)\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syJPTe5tsr2O",
        "outputId": "5b273e1f-db09-4af7-b9d4-e940c5d76b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GdLT0ZK1sy-q"
      },
      "outputs": [],
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i5WU3eWHs3hK"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        " real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "# Real labels are 1\n",
        " fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "# Fake labels are 0\n",
        " total_loss = real_loss + fake_loss\n",
        " return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nt3OCcPks68q"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        " return\n",
        " cross_entropy(tf.ones_like(fake_output),\n",
        "fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZFJtOwm-s9fD"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ypDdzpJms_1O"
      },
      "outputs": [],
      "source": [
        " seed = tf.random.normal([NUM_EXAMPLES_TO_GENERATE, NOISE_DIM])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XG__BOvotLcY"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(images):\n",
        "  noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    real_output = discriminator(images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    gen_loss = generator_loss(fake_output)\n",
        "    disc_loss = discriminator_loss(real_output, fake_output)\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "-llDltSatSUd"
      },
      "outputs": [],
      "source": [
        " def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        " # Produce images for the GIF as we go\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch {epoch + 1}/{epochs}')\n",
        "        generate_and_save_images(generator, epoch + 1, seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "oHPg-t9OtrQ5",
        "outputId": "b1ceb0c3-b4f9-4bac-8fe7-dbef3a9e1d49"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (<ipython-input-20-373f4a4b9734>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-373f4a4b9734>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    if (epoch + 1) % 10 == 0\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ],
      "source": [
        "def train(dataset, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        for image_batch in dataset:\n",
        "            train_step(image_batch)  # Ensure train_step is defined\n",
        "\n",
        "        # Produce images every 10 epochs for visualization\n",
        "        if (epoch + 1) % 10 == 0\n",
        "            print(f'Epoch {epoch + 1}/{epochs}')\n",
        "            generate_and_save_images(generator, epoch + 1, seed)  # Ensure generator and seed are defined\n",
        "\n",
        "# Call the train function\n",
        "train(train_dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWPXtGixgc9U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEjlw8+LjVHnxj07oRVKXV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}